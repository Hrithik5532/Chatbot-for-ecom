{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Title: Terms and Conditions - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/terms-conditions\\n\\nMarkdown Content:\\nPre-launch Terms and Conditions\\n-------------------------------\\n\\nWelcome to Zenrevo IT Solutions LLP's Prelaunch Campaign for Eshtyle!\\n\\nBy participating in our Pre Launch Campaign you agree to abide by these Terms and Conditions. Please read them carefully.\\n\\n1\\\\. Acceptance of Terms\\n-----------------------\\n\\nBy joining our waitlist, navigating our site for verification, and engaging with our offerings, you acknowledge that you have read, understood, and agreed to be bound by these Terms and Conditions, including any additional terms and conditions and policies referenced herein and/or available by hyperlink. These Terms and Conditions apply to all users of the site, including without limitation users who are browsers, vendors, customers, merchants, and/ or contributors of content.\\n\\n2\\\\. Pre Launch Campaign Participation\\n-------------------------------------\\n\\n*   Waitlist Registration: To participate in our pre launch campaign for Eshtyle, you must sign up for our waitlist. An email will be sent to the address you provide containing a link to our website for verification purposes.\\n*   Verification Process: Upon receiving our email, you must click on the verification link to confirm your email address and complete the registration process.\\n*   Benefits: After verification, you will be eligible for one (1) virtual try-on session and the opportunity to preorder selected t-shirts with free goodies worth up to INR 300. You may also pre-book a subscription to our virtual try-on service at discounted rates available exclusively during the pre launch period.\\n\\n3\\\\. Eligibility\\n---------------\\n\\nThis campaign is open to individuals who are 18 years of age or older. By participating, you confirm that you meet this age requirement.\\n\\n4\\\\. Campaign Period\\n-------------------\\n\\nThe prelaunch campaign for Eshtyle will run from 15 April 2024 to 25 April 2024. Zenrevo IT Solutions LLP reserves the right to extend or shorten the campaign period at our discretion.\\n\\n5\\\\. Offer Limitations\\n---------------------\\n\\nOffers are subject to availability and are limited to one per participant. The free virtual try-on session and goodies offer is non-transferable and cannot be exchanged for cash or other services. Preorder and subscription discounts are applicable only during the prelaunch period and cannot be combined with other offers.\\n\\n6\\\\. Data Protection\\n-------------------\\n\\nBy participating in the pre launch campaign for Eshtyle, you agree to our collection and use of your personal information for the purpose of campaign administration and as described in our Privacy Policy.\\n\\n7\\\\. Liability\\n-------------\\n\\nZenrevo IT Solutions LLP will not be liable for any damages or losses arising out of or in connection with your participation in the campaign for Eshtyle to the fullest extent permitted by law.\\n\\n8\\\\. Governing Law\\n-----------------\\n\\nThese Terms and Conditions are governed by the laws of India. Any disputes arising under or in connection with these Terms and Conditions shall be subject to the exclusive jurisdiction of the Indian courts.\\n\\n9\\\\. Amendments\\n--------------\\n\\nZenrevo IT Solutions LLP reserves the right to amend these Terms and Conditions at any time. Participants will be notified of any significant changes.\\n\\n10\\\\. Contact Us\\n---------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.\\n\\nWebsite is in construction! Once the website is ready, We will notify you.\\n\\nÂ© 2024 Copyright: [www.zenrevo.com](https://zenrevo.com/)\", metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='Title: Privacy Policy - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/privacy-policy\\n\\nMarkdown Content:\\nIntroduction\\n------------\\n\\nWelcome to Eshtyle by Zenrevo IT Solutions, a cutting-edge fashion e-commerce platform designed to offer personalized shopping experiences through customization and AI-driven design generation. Our mission is to revolutionize the way you engage with fashion, providing a space for creators to showcase their designs and for customers to create their unique style.\\n\\nInformation Collection\\n----------------------\\n\\nWe collect various types of personal information, including:\\n\\n*   Name and contact details\\n*   Payment information\\n*   Customization preferences and choices\\n*   Images and designs uploaded by creators and users\\n\\nData is collected directly from users, through cookies, and other technologies to enhance user experience and improve our services.\\n\\nUse of Information\\n------------------\\n\\nThe collected information is used to:\\n\\n*   Process transactions and customize products\\n*   Provide customer support and respond to inquiries\\n*   Generate AI-driven designs based on user preferences\\n\\nAll designs and customizations are processed with the utmost care to ensure your visions are accurately brought to life.\\n\\nSharing of Information\\n----------------------\\n\\nInformation may be shared with third parties under the following circumstances:\\n\\n*   Vendors for product customization\\n*   Business partners for plugin integration\\n\\nUser designs may also be featured on the platform, with proper consent, to inspire the community.\\n\\nData Protection\\n---------------\\n\\nWe employ various measures to protect user data, including encryption and access control. Our data retention and deletion policies ensure your information is handled responsibly.\\n\\nUser Rights\\n-----------\\n\\nUsers have the right to access, correct, or delete their personal information. For any such requests, please contact us through the information provided below.\\n\\nThird-Party Services\\n--------------------\\n\\nOur platform may include services from third parties, whose privacy practices are not covered by our policy. We encourage users to review these policies.\\n\\nInternational Data Transfers\\n----------------------------\\n\\nInformation may be transferred internationally. We ensure all data is protected with appropriate safeguards.\\n\\nChanges to the Privacy Policy\\n-----------------------------\\n\\nAny changes to our privacy policy will be communicated through our website and via email, where applicable.\\n\\nContact Information\\n-------------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.', metadata={'source': 'data\\\\terms.txt'}),\n",
       " Document(page_content='Title: Eshtyle | Virtual Try-On\\n\\nURL Source: https://eshtyle.com/virtual-try-on\\n\\nMarkdown Content:\\nHow to Use Our Virtual Try-On Feature !\\n---------------------------------------\\n\\nFollow these simple steps to see how you look in your selected outfit:\\n\\n1.  Select Your Image: Choose a full-body image of yourself. Ensure the image features only you, with a plain background for the best results.\\n2.  Choose Your Outfit: Browse through our collection and select the T-shirt design you\\'d like to try on.\\n3.  Submit Your Choices: Click on the \"Submit/Generate\" button to see how the outfit looks on you. Our AI will work its magic to dress you in your selected outfit.\\n4.  View Your Virtual Try-On: If our system is experiencing high demand, you\\'ll be placed in a queue. Don\\'t worry, we\\'ll email you once your virtual try-on is ready.\\n5.  Disclaimer for AI Limitations: Please note that the virtual try-on results are AI-generated and their accuracy may vary depending on image quality, lighting conditions, and pose.\\n\\nNote: If you\\'re not in a queue, your new look will be displayed directly on the website.', metadata={'source': 'data\\\\tryon.txt'})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "\n",
    "loader = DirectoryLoader('', glob=\"**/*.txt\",loader_cls=TextLoader)\n",
    "\n",
    "text_documents = loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# import bs4\n",
    "\n",
    "# loader = WebBaseLoader(web_paths=['https://eshtyle.com/terms-conditions','https://eshtyle.com/privacy-policy'],\n",
    "#                        bs_kwargs=dict(parse_only=bs4.SoupStrainer(\n",
    "# )))\n",
    "                    \n",
    "# loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Title: Terms and Conditions - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/terms-conditions\\n\\nMarkdown Content:\\nPre-launch Terms and Conditions\\n-------------------------------\\n\\nWelcome to Zenrevo IT Solutions LLP's Prelaunch Campaign for Eshtyle!\\n\\nBy participating in our Pre Launch Campaign you agree to abide by these Terms and Conditions. Please read them carefully.\\n\\n1\\\\. Acceptance of Terms\\n-----------------------\\n\\nBy joining our waitlist, navigating our site for verification, and engaging with our offerings, you acknowledge that you have read, understood, and agreed to be bound by these Terms and Conditions, including any additional terms and conditions and policies referenced herein and/or available by hyperlink. These Terms and Conditions apply to all users of the site, including without limitation users who are browsers, vendors, customers, merchants, and/ or contributors of content.\\n\\n2\\\\. Pre Launch Campaign Participation\\n-------------------------------------\\n\\n*   Waitlist Registration: To participate in our pre launch campaign for Eshtyle, you must sign up for our waitlist. An email will be sent to the address you provide containing a link to our website for verification purposes.\\n*   Verification Process: Upon receiving our email, you must click on the verification link to confirm your email address and complete the registration process.\\n*   Benefits: After verification, you will be eligible for one (1) virtual try-on session and the opportunity to preorder selected t-shirts with free goodies worth up to INR 300. You may also pre-book a subscription to our virtual try-on service at discounted rates available exclusively during the pre launch period.\\n\\n3\\\\. Eligibility\\n---------------\\n\\nThis campaign is open to individuals who are 18 years of age or older. By participating, you confirm that you meet this age requirement.\\n\\n4\\\\. Campaign Period\\n-------------------\\n\\nThe prelaunch campaign for Eshtyle will run from 15 April 2024 to 25 April 2024. Zenrevo IT Solutions LLP reserves the right to extend or shorten the campaign period at our discretion.\\n\\n5\\\\. Offer Limitations\\n---------------------\\n\\nOffers are subject to availability and are limited to one per participant. The free virtual try-on session and goodies offer is non-transferable and cannot be exchanged for cash or other services. Preorder and subscription discounts are applicable only during the prelaunch period and cannot be combined with other offers.\\n\\n6\\\\. Data Protection\\n-------------------\\n\\nBy participating in the pre launch campaign for Eshtyle, you agree to our collection and use of your personal information for the purpose of campaign administration and as described in our Privacy Policy.\\n\\n7\\\\. Liability\\n-------------\\n\\nZenrevo IT Solutions LLP will not be liable for any damages or losses arising out of or in connection with your participation in the campaign for Eshtyle to the fullest extent permitted by law.\\n\\n8\\\\. Governing Law\\n-----------------\\n\\nThese Terms and Conditions are governed by the laws of India. Any disputes arising under or in connection with these Terms and Conditions shall be subject to the exclusive jurisdiction of the Indian courts.\\n\\n9\\\\. Amendments\\n--------------\\n\\nZenrevo IT Solutions LLP reserves the right to amend these Terms and Conditions at any time. Participants will be notified of any significant changes.\\n\\n10\\\\. Contact Us\\n---------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.\\n\\nWebsite is in construction! Once the website is ready, We will notify you.\\n\\nÂ© 2024 Copyright: [www.zenrevo.com](https://zenrevo.com/)\", metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='Title: Privacy Policy - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/privacy-policy\\n\\nMarkdown Content:\\nIntroduction\\n------------\\n\\nWelcome to Eshtyle by Zenrevo IT Solutions, a cutting-edge fashion e-commerce platform designed to offer personalized shopping experiences through customization and AI-driven design generation. Our mission is to revolutionize the way you engage with fashion, providing a space for creators to showcase their designs and for customers to create their unique style.\\n\\nInformation Collection\\n----------------------\\n\\nWe collect various types of personal information, including:\\n\\n*   Name and contact details\\n*   Payment information\\n*   Customization preferences and choices\\n*   Images and designs uploaded by creators and users\\n\\nData is collected directly from users, through cookies, and other technologies to enhance user experience and improve our services.\\n\\nUse of Information\\n------------------\\n\\nThe collected information is used to:\\n\\n*   Process transactions and customize products\\n*   Provide customer support and respond to inquiries\\n*   Generate AI-driven designs based on user preferences\\n\\nAll designs and customizations are processed with the utmost care to ensure your visions are accurately brought to life.\\n\\nSharing of Information\\n----------------------\\n\\nInformation may be shared with third parties under the following circumstances:\\n\\n*   Vendors for product customization\\n*   Business partners for plugin integration\\n\\nUser designs may also be featured on the platform, with proper consent, to inspire the community.\\n\\nData Protection\\n---------------\\n\\nWe employ various measures to protect user data, including encryption and access control. Our data retention and deletion policies ensure your information is handled responsibly.\\n\\nUser Rights\\n-----------\\n\\nUsers have the right to access, correct, or delete their personal information. For any such requests, please contact us through the information provided below.\\n\\nThird-Party Services\\n--------------------\\n\\nOur platform may include services from third parties, whose privacy practices are not covered by our policy. We encourage users to review these policies.\\n\\nInternational Data Transfers\\n----------------------------\\n\\nInformation may be transferred internationally. We ensure all data is protected with appropriate safeguards.\\n\\nChanges to the Privacy Policy\\n-----------------------------\\n\\nAny changes to our privacy policy will be communicated through our website and via email, where applicable.\\n\\nContact Information\\n-------------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.', metadata={'source': 'data\\\\terms.txt'}),\n",
       " Document(page_content='Title: Eshtyle | Virtual Try-On\\n\\nURL Source: https://eshtyle.com/virtual-try-on\\n\\nMarkdown Content:\\nHow to Use Our Virtual Try-On Feature !\\n---------------------------------------\\n\\nFollow these simple steps to see how you look in your selected outfit:\\n\\n1.  Select Your Image: Choose a full-body image of yourself. Ensure the image features only you, with a plain background for the best results.\\n2.  Choose Your Outfit: Browse through our collection and select the T-shirt design you\\'d like to try on.\\n3.  Submit Your Choices: Click on the \"Submit/Generate\" button to see how the outfit looks on you. Our AI will work its magic to dress you in your selected outfit.\\n4.  View Your Virtual Try-On: If our system is experiencing high demand, you\\'ll be placed in a queue. Don\\'t worry, we\\'ll email you once your virtual try-on is ready.\\n5.  Disclaimer for AI Limitations: Please note that the virtual try-on results are AI-generated and their accuracy may vary depending on image quality, lighting conditions, and pose.\\n\\nNote: If you\\'re not in a queue, your new look will be displayed directly on the website.', metadata={'source': 'data\\\\tryon.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Title: Terms and Conditions - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/terms-conditions\\n\\nMarkdown Content:\\nPre-launch Terms and Conditions\\n-------------------------------\\n\\nWelcome to Zenrevo IT Solutions LLP's Prelaunch Campaign for Eshtyle!\\n\\nBy participating in our Pre Launch Campaign you agree to abide by these Terms and Conditions. Please read them carefully.\\n\\n1\\\\. Acceptance of Terms\\n-----------------------\\n\\nBy joining our waitlist, navigating our site for verification, and engaging with our offerings, you acknowledge that you have read, understood, and agreed to be bound by these Terms and Conditions, including any additional terms and conditions and policies referenced herein and/or available by hyperlink. These Terms and Conditions apply to all users of the site, including without limitation users who are browsers, vendors, customers, merchants, and/ or contributors of content.\\n\\n2\\\\. Pre Launch Campaign Participation\\n-------------------------------------\", metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='*   Waitlist Registration: To participate in our pre launch campaign for Eshtyle, you must sign up for our waitlist. An email will be sent to the address you provide containing a link to our website for verification purposes.\\n*   Verification Process: Upon receiving our email, you must click on the verification link to confirm your email address and complete the registration process.\\n*   Benefits: After verification, you will be eligible for one (1) virtual try-on session and the opportunity to preorder selected t-shirts with free goodies worth up to INR 300. You may also pre-book a subscription to our virtual try-on service at discounted rates available exclusively during the pre launch period.\\n\\n3\\\\. Eligibility\\n---------------\\n\\nThis campaign is open to individuals who are 18 years of age or older. By participating, you confirm that you meet this age requirement.\\n\\n4\\\\. Campaign Period\\n-------------------', metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='The prelaunch campaign for Eshtyle will run from 15 April 2024 to 25 April 2024. Zenrevo IT Solutions LLP reserves the right to extend or shorten the campaign period at our discretion.\\n\\n5\\\\. Offer Limitations\\n---------------------\\n\\nOffers are subject to availability and are limited to one per participant. The free virtual try-on session and goodies offer is non-transferable and cannot be exchanged for cash or other services. Preorder and subscription discounts are applicable only during the prelaunch period and cannot be combined with other offers.\\n\\n6\\\\. Data Protection\\n-------------------\\n\\nBy participating in the pre launch campaign for Eshtyle, you agree to our collection and use of your personal information for the purpose of campaign administration and as described in our Privacy Policy.\\n\\n7\\\\. Liability\\n-------------', metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='Zenrevo IT Solutions LLP will not be liable for any damages or losses arising out of or in connection with your participation in the campaign for Eshtyle to the fullest extent permitted by law.\\n\\n8\\\\. Governing Law\\n-----------------\\n\\nThese Terms and Conditions are governed by the laws of India. Any disputes arising under or in connection with these Terms and Conditions shall be subject to the exclusive jurisdiction of the Indian courts.\\n\\n9\\\\. Amendments\\n--------------\\n\\nZenrevo IT Solutions LLP reserves the right to amend these Terms and Conditions at any time. Participants will be notified of any significant changes.\\n\\n10\\\\. Contact Us\\n---------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.\\n\\nWebsite is in construction! Once the website is ready, We will notify you.\\n\\nÂ© 2024 Copyright: [www.zenrevo.com](https://zenrevo.com/)', metadata={'source': 'data\\\\privacy.txt'}),\n",
       " Document(page_content='Title: Privacy Policy - Eshtyle by Zenrevo IT Solutions\\n\\nURL Source: https://eshtyle.com/privacy-policy\\n\\nMarkdown Content:\\nIntroduction\\n------------\\n\\nWelcome to Eshtyle by Zenrevo IT Solutions, a cutting-edge fashion e-commerce platform designed to offer personalized shopping experiences through customization and AI-driven design generation. Our mission is to revolutionize the way you engage with fashion, providing a space for creators to showcase their designs and for customers to create their unique style.\\n\\nInformation Collection\\n----------------------\\n\\nWe collect various types of personal information, including:\\n\\n*   Name and contact details\\n*   Payment information\\n*   Customization preferences and choices\\n*   Images and designs uploaded by creators and users\\n\\nData is collected directly from users, through cookies, and other technologies to enhance user experience and improve our services.\\n\\nUse of Information\\n------------------\\n\\nThe collected information is used to:', metadata={'source': 'data\\\\terms.txt'}),\n",
       " Document(page_content='*   Process transactions and customize products\\n*   Provide customer support and respond to inquiries\\n*   Generate AI-driven designs based on user preferences\\n\\nAll designs and customizations are processed with the utmost care to ensure your visions are accurately brought to life.\\n\\nSharing of Information\\n----------------------\\n\\nInformation may be shared with third parties under the following circumstances:\\n\\n*   Vendors for product customization\\n*   Business partners for plugin integration\\n\\nUser designs may also be featured on the platform, with proper consent, to inspire the community.\\n\\nData Protection\\n---------------\\n\\nWe employ various measures to protect user data, including encryption and access control. Our data retention and deletion policies ensure your information is handled responsibly.\\n\\nUser Rights\\n-----------\\n\\nUsers have the right to access, correct, or delete their personal information. For any such requests, please contact us through the information provided below.', metadata={'source': 'data\\\\terms.txt'}),\n",
       " Document(page_content='Third-Party Services\\n--------------------\\n\\nOur platform may include services from third parties, whose privacy practices are not covered by our policy. We encourage users to review these policies.\\n\\nInternational Data Transfers\\n----------------------------\\n\\nInformation may be transferred internationally. We ensure all data is protected with appropriate safeguards.\\n\\nChanges to the Privacy Policy\\n-----------------------------\\n\\nAny changes to our privacy policy will be communicated through our website and via email, where applicable.\\n\\nContact Information\\n-------------------\\n\\nFor any queries or concerns regarding the prelaunch campaign for Eshtyle or these Terms and Conditions, please contact us at support@eshtyle.com.', metadata={'source': 'data\\\\terms.txt'}),\n",
       " Document(page_content='Title: Eshtyle | Virtual Try-On\\n\\nURL Source: https://eshtyle.com/virtual-try-on\\n\\nMarkdown Content:\\nHow to Use Our Virtual Try-On Feature !\\n---------------------------------------\\n\\nFollow these simple steps to see how you look in your selected outfit:', metadata={'source': 'data\\\\tryon.txt'}),\n",
       " Document(page_content='1.  Select Your Image: Choose a full-body image of yourself. Ensure the image features only you, with a plain background for the best results.\\n2.  Choose Your Outfit: Browse through our collection and select the T-shirt design you\\'d like to try on.\\n3.  Submit Your Choices: Click on the \"Submit/Generate\" button to see how the outfit looks on you. Our AI will work its magic to dress you in your selected outfit.\\n4.  View Your Virtual Try-On: If our system is experiencing high demand, you\\'ll be placed in a queue. Don\\'t worry, we\\'ll email you once your virtual try-on is ready.\\n5.  Disclaimer for AI Limitations: Please note that the virtual try-on results are AI-generated and their accuracy may vary depending on image quality, lighting conditions, and pose.\\n\\nNote: If you\\'re not in a queue, your new look will be displayed directly on the website.', metadata={'source': 'data\\\\tryon.txt'})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=10)\n",
    "document = text_splitter.split_documents(text_documents)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "                                                      model_kwargs={\"device\": \"cpu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "\n",
    "# embeddings = embeddings(\n",
    "#     query_instruction=\"Represent the query for retrieval: \"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore  = Chroma.from_documents(document,instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FAISS Vector Database\n",
    "from langchain_community.vectorstores import FAISS\n",
    "db = FAISS.from_documents(document, instructor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags=['FAISS', 'HuggingFaceInstructEmbeddings'] vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000002B17FBB9850> search_kwargs={'k': 3}\n"
     ]
    }
   ],
   "source": [
    "retriever=db.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})\n",
    "print(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Subjective Perspectives:**\\n\\n* Finding purpose and meaning through personal values, experiences, and beliefs\\n* Creating a positive impact on the world and leaving a legacy\\n* Experiencing joy, love, and fulfillment in life\\n* Connecting with others and forming meaningful relationships\\n\\n**Objective Perspectives:**\\n\\n* **Evolutionary Approach:** The meaning of life is to survive, reproduce, and ensure the continuation of the species.\\n* **Cognitive Approach:** The meaning of life is a subjective construct created by individuals to make sense of their existence.\\n* **Philosophical Approaches:**\\n    * **Existentialism:** Life has no inherent meaning, and individuals must create their own.\\n    * **Purpose-Driven:** Life has an objective purpose, such as finding God or contributing to society.\\n    * **Buddhism:** The meaning of life is to end suffering and achieve enlightenment.\\n\\n**Cultural and Social Perspectives:**\\n\\n* Different cultures and societies have varying beliefs about the meaning of life, influenced by religious, philosophical, and social norms.\\n* Some cultures emphasize community and social harmony, while others focus on individual achievement and happiness.\\n\\n**Personal Reflections:**\\n\\n* The meaning of life is a personal journey that involves introspection, self-discovery, and aligning actions with values.\\n* It is an ongoing search that may change over time as individuals grow and evolve.\\n* There is no one \"right\" answer, and the meaning of life is ultimately a matter of individual choice and experience.\\n\\n**Common Themes:**\\n\\nDespite the diversity of perspectives, there are common themes that emerge:\\n\\n* **Purpose:** Having a sense of purpose and direction in life.\\n* **Connection:** Building meaningful relationships and fostering a sense of belonging.\\n* **Growth:** Continuously learning, developing, and evolving as a person.\\n* **Contribution:** Making a positive impact on the world and leaving a legacy.\\n* **Happiness:** Experiencing joy, fulfillment, and a sense of well-being.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyCHHVhVlcfWQd33H9-CLvBZph41SHn3UsQ')\n",
    "model = genai.GenerativeModel('gemini-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attenton` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 201326592 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/Phi-3-mini-4k-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmicrosoft/Phi-3-mini-4k-instruct\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:558\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    557\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    562\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\modeling_utils.py:3550\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3544\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[0;32m   3545\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[0;32m   3546\u001b[0m )\n\u001b[0;32m   3548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[0;32m   3549\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[1;32m-> 3550\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3552\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[0;32m   3553\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\cc80d6ce9f0f8dd000b39913b8f65427f093576d\\modeling_phi3.py:1206\u001b[0m, in \u001b[0;36mPhi3ForCausalLM.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(config)\n\u001b[1;32m-> 1206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mPhi3Model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mvocab_size\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mhidden_size, config\u001b[38;5;241m.\u001b[39mvocab_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\cc80d6ce9f0f8dd000b39913b8f65427f093576d\\modeling_phi3.py:1047\u001b[0m, in \u001b[0;36mPhi3Model.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m-> 1047\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mPhi3DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   1048\u001b[0m )\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_attn_implementation\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m Phi3RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\cc80d6ce9f0f8dd000b39913b8f65427f093576d\\modeling_phi3.py:1047\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mEmbedding(config\u001b[38;5;241m.\u001b[39mvocab_size, config\u001b[38;5;241m.\u001b[39mhidden_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39membd_pdrop)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList(\n\u001b[1;32m-> 1047\u001b[0m     [\u001b[43mPhi3DecoderLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mnum_hidden_layers)]\n\u001b[0;32m   1048\u001b[0m )\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_attn_implementation\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m Phi3RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\cc80d6ce9f0f8dd000b39913b8f65427f093576d\\modeling_phi3.py:841\u001b[0m, in \u001b[0;36mPhi3DecoderLayer.__init__\u001b[1;34m(self, config, layer_idx)\u001b[0m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn \u001b[38;5;241m=\u001b[39m PHI3_ATTENTION_CLASSES[config\u001b[38;5;241m.\u001b[39m_attn_implementation](config, layer_idx\u001b[38;5;241m=\u001b[39mlayer_idx)\n\u001b[1;32m--> 841\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp \u001b[38;5;241m=\u001b[39m \u001b[43mPhi3MLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm \u001b[38;5;241m=\u001b[39m Phi3RMSNorm(config\u001b[38;5;241m.\u001b[39mhidden_size, eps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrms_norm_eps)\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresid_attn_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(config\u001b[38;5;241m.\u001b[39mresid_pdrop)\n",
      "File \u001b[1;32m~\\.cache\\huggingface\\modules\\transformers_modules\\microsoft\\Phi-3-mini-4k-instruct\\cc80d6ce9f0f8dd000b39913b8f65427f093576d\\modeling_phi3.py:265\u001b[0m, in \u001b[0;36mPhi3MLP.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_up_proj \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(config\u001b[38;5;241m.\u001b[39mintermediate_size, config\u001b[38;5;241m.\u001b[39mhidden_size, bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn \u001b[38;5;241m=\u001b[39m ACT2FN[config\u001b[38;5;241m.\u001b[39mhidden_act]\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfactory_kwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 201326592 bytes."
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import (\n",
    "     ConversationalRetrievalChain\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chain \u001b[38;5;241m=\u001b[39m \u001b[43mConversationalRetrievalChain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_llm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_source_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\conversational_retrieval\\base.py:372\u001b[0m, in \u001b[0;36mConversationalRetrievalChain.from_llm\u001b[1;34m(cls, llm, retriever, condense_question_prompt, chain_type, verbose, condense_question_llm, combine_docs_chain_kwargs, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convenience method to load chain from LLM and retriever.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03mThis provides some logic to create the `question_generator` chain\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03m        ConversationalRetrievalChain\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    371\u001b[0m combine_docs_chain_kwargs \u001b[38;5;241m=\u001b[39m combine_docs_chain_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 372\u001b[0m doc_chain \u001b[38;5;241m=\u001b[39m \u001b[43mload_qa_chain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchain_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchain_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcombine_docs_chain_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m _llm \u001b[38;5;241m=\u001b[39m condense_question_llm \u001b[38;5;129;01mor\u001b[39;00m llm\n\u001b[0;32m    381\u001b[0m condense_question_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m    382\u001b[0m     llm\u001b[38;5;241m=\u001b[39m_llm,\n\u001b[0;32m    383\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mcondense_question_prompt,\n\u001b[0;32m    384\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    385\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    386\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:249\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[1;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m     )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchain_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:73\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[1;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_stuff_chain\u001b[39m(\n\u001b[0;32m     64\u001b[0m     llm: BaseLanguageModel,\n\u001b[0;32m     65\u001b[0m     prompt: Optional[BasePromptTemplate] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m     71\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StuffDocumentsChain:\n\u001b[0;32m     72\u001b[0m     _prompt \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;129;01mor\u001b[39;00m stuff_prompt\u001b[38;5;241m.\u001b[39mPROMPT_SELECTOR\u001b[38;5;241m.\u001b[39mget_prompt(llm)\n\u001b[1;32m---> 73\u001b[0m     llm_chain \u001b[38;5;241m=\u001b[39m \u001b[43mLLMChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StuffDocumentsChain(\n\u001b[0;32m     82\u001b[0m         llm_chain\u001b[38;5;241m=\u001b[39mllm_chain,\n\u001b[0;32m     83\u001b[0m         document_variable_name\u001b[38;5;241m=\u001b[39mdocument_variable_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     88\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mc:\\Users\\91908\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for LLMChain\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)\nllm\n  instance of Runnable expected (type=type_error.arbitrary_type; expected_arbitrary_type=Runnable)"
     ]
    }
   ],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "        model ,\n",
    "        retriever,\n",
    "        return_source_documents=True,\n",
    "        max_tokens_limit=3500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
